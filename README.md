# ðŸš€ Gargantuan Takeout Rocket

WIP STATUS NOT READY YET AND SO IS THIS GUIDE

*Liftoff from Google into the Azure, very fast*

Gargantuan Takeout Rocket (GTR) is a toolkit of instructions/guides and software to help you take out your data from Google Takeout and put it somewhere *else* safe easily, periodically, and fast.

At the moment, the only backup destination is Microsoft Azure Blob Storage due to Azure's unique ["Put Block From URL"][pbfu] API which allows commanding Azure to download from a remote source. Cloudflare Workers are used to work around a [URL escaping bug][azbesc] and the [HTTP 1.1 limitation][azb11] in the Azure Blob Storage API. With this guide, software, and setup, you can achieve speeds of up to 6GB/s from Google Takeout to Azure Blob Storage Archive Tier with little periodic setup, making it easy and more probable to do the **right** thing of periodically backing up your Google account.

GTR is not a fully automated solution as that is impossible with Google Takeout's anti-automation measures, but is an assistive solution. GTR takes a less than an hour to setup and less than 10 minutes every 3 months to use.

The original author of GTR's Google account is about 1.25TB in size (80% Youtube Videos, 20% other, Google Photos ~200GB). Pre-GTR, the backup procedure would have taken at least 3 hours even with a [VPS Setup][vps_fxp] facilitating the transfer from Google Takeout as even large instances on the cloud with large disks and many CPUs would eventually choke with too many files being downloaded in parallel. It was also depressingly high-touch and toilsome, requiring many clicks, reauthorizations, and download environment setup. By delegating the task to Azure with assists from CloudFlare workers and a custom browser extension that makes up GTR, the original author is able to transfer the 1.25TB of 50GB Google Takeout files to Azure Storage in 3 minutes.

GTR is right for you if:

* You have a lot of data on Google Takeout and Google Takeout-compatible properties such as YouTube.
  * If you think you have "a lot", then you have "a lot", be it 5GB or 5TB.
* You generally intend to continue to use Google services.
  * This is generally not a one-time evacuation from Google.
* You want to have access to your data in case something bad happens to your Google account such as an errant automated banning action.
  * Hopefully it won't happen to you but it seems a lot of control is outside of our hands nowadays anyway.
* You want to backup your account to somewhere that else isn't Google and are OK with Microsoft.
  * You don't need to like Microsoft. You just need to be accepting.
* You want to back it up somewhere cheap.
  * Azure Blob Storage Archive class costs about $0.99 per TB per month. The built-in targets of Google Takeout can't match this at all. The pricing is identical to AWS Deep Archive.
* You have a to-do app or calendar app that can make recurring tasks every 3 months.
  * This is an assistive solution which still requires human assistance.
* You are OK with backing their Google Data to somewhere archival-oriented and not interested in looking at their backups unless something really bad actually happens.
  * Downloads from the Archive class will cost money. There are also outgoing bandwidth fees from Azure as well. It is possible to inspect the data while it is in Hot tier though through a cloud instance.
* You don't want to spin up cloud compute instances and send commands and whatnot.
  * It may be a pet that won't live very long but it's still a pet.
  * The time it takes to setup the environment and to facilitate the transfer by hand on the instance wastes the time we have with such large instance resources when we aren't transferring.
* You want to quickly transfer out at 5GB/s, in parallel, outward.
  * The highest speed seen documented with VPS Setups have been [around 65MB/s][congdon].
* You have a slow internet connection.
  * The transfers can be completely done over tethering over a cell phone.
* You don't have the space to temporaily store the data.
  * Not all of us have large hard drives in large computers locally.

## Preparation

TODO

init takeout a day before

setup azure container with lifecycle rules

optional: setup gtr-proxy in own cloudflare account

get sas url

install extension

enable extension

paste sas url

download all takeout links

check files exist

disable extension

set calendar/todo app repeat

## TODO

* Cleanup Extension
* Investigate Azure Encryption Key Stuff. Have Azure encrypt at rest with a public key?
* Document Document Document Refine

## Social Posts of Interest

### "Google banned my account!"

* https://news.ycombinator.com/item?id=24965432

### Complaints about Takeout being hard to use

just search twitter
### Other people backing up to cloud storage and their setups.

A future version of GTR may include S3 and S3-compatible APIs as a destination. There may be a possiblity to teach Cloudflare Workers to facilitate this in a highly parallel manner.

In the meantime:

* https://gunargessner.com/takeout

* https://sjwheel.net/cloud/computing/2019/08/01/aws_backup.html

* https://benjamincongdon.me/blog/2021/05/03/Backing-up-my-Google-Takeout-data/

The general idea of these is to use a single EC2/VPS instance to handle the coordination and traffic. Congdon's solution clocked in at about 65MB/s.


[vps_fxp]: https://sjwheel.net/cloud/computing/2019/08/01/aws_backup.html
[pbfu]: https://docs.microsoft.com/en-us/rest/api/storageservices/put-block-from-url
[azb11]: https://docs.microsoft.com/en-us/rest/api/storageservices/http-version-support
[azbesc]: https://docs.microsoft.com/en-us/answers/questions/641723/i-can39t-get-azure-storage-to-support-putting-data.html
[congdon]: https://benjamincongdon.me/blog/2021/05/03/Backing-up-my-Google-Takeout-data/]
